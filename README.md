# Material Stream Identification System â™»ï¸

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)

## ğŸ“Œ Project Overview
This project implements an **Automated Material Stream Identification (MSI) System** designed to classify post-consumer waste into specific material categories. The system emphasizes the mastery of the entire ML pipeline: Data Preprocessing, Feature Extraction, Classifier Training, and Performance Evaluation.

The solution includes a comparative analysis between **Support Vector Machines (SVM)** and **k-Nearest Neighbors (k-NN)**, and features a deployment module for real-time classification using a live camera feed.

## ğŸ¯ Objectives
* **Data Augmentation:** Increase the training dataset size by a minimum of 30% using geometric and color transformations.
* **Feature Extraction:** Convert raw images into 1D numerical feature vectors using distinct descriptors (e.g., HOG, Color Histograms).
* **Robust Classification:** Classify items into 7 categories with a target validation accuracy of **0.85**.
* **Out-of-Distribution Detection:** Implement a rejection mechanism to classify low-confidence or blurred inputs as "Unknown".

## ğŸ—‚ï¸ Dataset & Classes
The model classifies input images into the following 7 classes:

| ID | Class | Description |
| :--- | :--- | :--- |
| **0** | **Glass** | Bottles, jars, amorphous solid materials. |
| **1** | **Paper** | Newspapers, office paper, pressed cellulose. |
| **2** | **Cardboard** | Heavy-duty structured material. |
| **3** | **Plastic** | Water bottles, films, organic compounds. |
| **4** | **Metal** | Cans, steel scrap, metallic substances. |
| **5** | **Trash** | Non-recyclable or contaminated waste. |
| **6** | **Unknown** | Out-of-distribution items, blurred inputs, or low-confidence predictions. |

## ğŸ—ï¸ Project Structure
The project follows a modular **Strategy Pattern** design to allow easy swapping of feature extractors and classifiers.

```text
Materials-Identification-Project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # Original images (0-Glass, 1-Paper, etc.)
â”‚   â””â”€â”€ processed/             # Augmented images  and extracted features
â”‚
â”œâ”€â”€ models/                    # Saved model weights (.pkl/.joblib) 
â”‚   â”œâ”€â”€ svm_best_model.pkl
â”‚   â””â”€â”€ knn_best_model.pkl
â”‚
â”œâ”€â”€ notebooks/                 # Jupyter notebooks for experiments & plotting
â”‚   â”œâ”€â”€ 01_augmentation_demo.ipynb
â”‚   â”œâ”€â”€ 02_feature_extraction_comparison.ipynb
â”‚   â””â”€â”€ 03_model_evaluation.ipynb
â”‚
â”œâ”€â”€ src/                       # Core Source Code (The Library)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ augmentation.py        # Code to increase dataset size by 30% 
â”‚   â”œâ”€â”€ features/              # Feature Extraction Strategies 
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py            # Abstract Base Class (Interface)
â”‚   â”‚   â”œâ”€â”€ hog.py             # Concrete Strategy A
â”‚   â”‚   â””â”€â”€ color_hist.py      # Concrete Strategy B
â”‚   â”œâ”€â”€ classifiers/           # Classification Strategies [cite: 23]
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py            # Abstract Base Class (Interface)
â”‚   â”‚   â”œâ”€â”€ svm_wrapper.py     # SVM Implementation [cite: 49]
â”‚   â”‚   â””â”€â”€ knn_wrapper.py     # k-NN Implementation [cite: 51]
â”‚   â””â”€â”€ utils.py               # Helper functions (file loading, resizing)
â”‚
â”œâ”€â”€ deploy.py                  # The real-time camera application 
â”œâ”€â”€ train.py                   # Script to run the full training pipeline
â”œâ”€â”€ requirements.txt           # List of libraries (opencv, sklearn, numpy)
â”œâ”€â”€ README.md                  # Documentation for the Git repo 
â””â”€â”€ .gitignore                 # Important: Ignore /data and /models
```

## âš™ï¸ Installation & Usage
1. Clone the repository:
```bash
git clone [https://github.com/](https://github.com/)[YourUsername]/Material-Stream-Identification.git
cd Material-Stream-Identification
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```
3. Train the models:
```bash
python train.py --model svm --features hog
```

4. Run Real-Time Deployment: To start the live camera classification:
```bash
python deploy.py
```

## ğŸ‘¥ Team Members
[Ziad Ismael]

[Omar Sameh]

[Mohamed Khamis]

[Mohannad ElBendary]

## ğŸ“ Acknowledgment
This project is part of the Machine Learning Course at the Faculty of Computing and Artificial Intelligence, Cairo University (FCAI-CU).